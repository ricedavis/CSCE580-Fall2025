{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c1ec5a",
   "metadata": {},
   "source": [
    "# Lab 3: Bias-Variance Decomposition\n",
    "\n",
    "In prior labs we've looked at errors made by our classifiers, and considered the\n",
    "way these mistakes might impact groups we care about in our data. In this lab,\n",
    "we will explore more to understand these errors with respect to models that\n",
    "have been seen previously, and assess how changes in hyperparameters in our \n",
    "models can affect these errors. We will continue to use the NHANES dataset.\n",
    "\n",
    "Two major sources of error that we can, in theory, work to control\n",
    "are **bias** and **variance**. As you learned in class, bias occurs\n",
    "when our predictions reflect underlying assumptions about our model,\n",
    "regardless of the training data. For example, if we are making predictions\n",
    "using a linear regression model, we must assume linearity between our input\n",
    "features and our target. But relationships between features and targets\n",
    "are often far from linear. This means that if our model is constrained\n",
    "to make linear predictions when true relationships between features and\n",
    "targets are non-linear, our predictions will be biased in favour of our\n",
    "modelling assumptions. \n",
    "\n",
    "On the other hand, it might be the case that we train a model that very\n",
    "accurately captures the relationship between our features and target\n",
    "in a small set of training data. While this might seem desirable, if\n",
    "our training data does not reflect our test data, our model may not\n",
    "reflect relationships between the features and target in test data.\n",
    "This source of error is due the fact that we have tailored our model\n",
    "to capture relationships in a small, but non-representative, set of\n",
    "data. If we have this kind of a variance issue, our model may end up\n",
    "being very sensitive to small fluctuations in the training set that we\n",
    "choose.\n",
    "\n",
    "Ideally, we want to reduce **both** sources of error. If we manage to\n",
    "reduce both, then we can build more accurate models. But how do we\n",
    "diagnose bias and variance issues in the first place?  And what should\n",
    "we do about the issues? And how can we be sure that our \"fixes\"\n",
    "mitigate the risks that might be associated with our model's use?\n",
    "\n",
    "By the end of this lab you will be able to:\n",
    "\n",
    "1. How to assess bias and variance in errors in a synthetic regression and\n",
    "   real-world classification example;\n",
    "2. How bias and variance can be related to model complexity;\n",
    "3. How bias and variance can be related to choices of features;\n",
    "4. Some of the limitations to analyses of bias and variance, in particular as related to risk.\n",
    "\n",
    "Thanks to https://www.kaggle.com/code/tobyanderson/health-survey-analysis for some utilities to decode NHANES categories!  \n",
    "\n",
    "## Google Colab Setup\n",
    "\n",
    "As before, we will import `matplotlib`, `numpy`, and `pandas` for plotting, linear algebra manipulations, and manipulating tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f6013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # For plotting\n",
    "import numpy as np              # Linear algebra library\n",
    "import pandas as pd             # For manipulating tabular data\n",
    "import random                   # for random number generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f64f1a8",
   "metadata": {},
   "source": [
    "## Part 1. Synthetic Data Demonstration\n",
    "\n",
    "In this section, we will study bias and variance in some synthetic data\n",
    "so that we can control the way that data is generated, so the data generation\n",
    "distribution is known.\n",
    "We will generate some figures to help us reason numerically about bias and variance.\n",
    "\n",
    "We will use linear regression with a polynomial feature\n",
    "mapping, and reason about how the degree of the polynomial $M$ affects the\n",
    "various sources of error.\n",
    "\n",
    "The first thing we will do is define the data generation distribution\n",
    "from which our data sets will be drawn.\n",
    "To make it easy to visualize our data, the data set will contain\n",
    "one input feature $x$, and there will be one target feature $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc2c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt(x, noise=True):\n",
    "    \"\"\"\n",
    "    Obtain the ground truth value t for an input feature with value x.\n",
    "    Note that there is some noise in t, unless excluded.\n",
    "\n",
    "    Parameters:\n",
    "        `x`     - a numpy array of input features\n",
    "                  the values should be between 0 and 100\n",
    "        `noise` - whether to include noise \n",
    "\n",
    "    Returns: The target `t` corresponding to each `x`. This is a np.array\n",
    "             with the same shape as `x`\n",
    "    \"\"\"\n",
    "    # the target is a polynomial function o the input data, plus noise\n",
    "    t = x**2 - 0.25 * x**2.3 + int(noise) * np.random.normal(0, 25, size=x.shape)\n",
    "    return t\n",
    "\n",
    "# generate input data that covers the range that we support: [0, 100]\n",
    "xs_all       = np.linspace(0,100,1000)\n",
    "ts_all       = get_gt(xs_all)\n",
    "ts_noiseless = get_gt(xs_all, noise=False)\n",
    "plt.plot(xs_all, ts_all, 'b.')      # data with noise\n",
    "plt.plot(xs_all, ts_noiseless, 'r') # data without noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e126dea",
   "metadata": {},
   "source": [
    "You can see that our data is obviously structured and it looks more or less like\n",
    "it follows a quadratic curve. But the structure may be a little hard to determine\n",
    "if we only have a few samples in hand, since the small number of samples\n",
    "may not accurately reflect data variation across the entire set.\n",
    "\n",
    "To illustrate, let's start with one more function that will sample a small\n",
    "number of data points (both input + output features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee811d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(size):\n",
    "    \"\"\"\n",
    "    Sample data points from our distribution.\n",
    "\n",
    "    Parameters:\n",
    "        `size`    - represents the np.array size of both the input and targets\n",
    "\n",
    "    Returns: A tuple `(xs, ts)`, both numpy arrays with shape provided by `size` \n",
    "    \"\"\"\n",
    "    xs = np.random.uniform(0, 100, size=size)\n",
    "    return xs, get_gt(xs)\n",
    "\n",
    "# generate a small number of input data, which may not reflect\n",
    "# the data variation across the entire dataset\n",
    "xs, ts  = sample_data(size=(10,))\n",
    "plt.plot(xs, ts, 'b.') # data with noise\n",
    "plt.plot(xs_all, ts_noiseless, 'r') # data without noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef5a62",
   "metadata": {},
   "source": [
    "Now, we will explore the sources of error when we learn a polynomial regression\n",
    "model from a data sample. First, we will use some `sklearn` functions to perform\n",
    "the feature mapping transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "M    = 2                     # the degree of our polynomial\n",
    "poly = PolynomialFeatures(M) # feature mapping fn\n",
    "\n",
    "xs_fets_all = poly.fit_transform(np.array(xs_all).reshape(-1, 1))\n",
    "print(xs_all.shape)      # should be (1000,)\n",
    "print(xs_fets_all.shape) # should be (1000, M+1)\n",
    "print(xs_fets_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886b16fe",
   "metadata": {},
   "source": [
    "With the feature mapping in place, we can see what a polynomial model\n",
    "built on these data points look like below.\n",
    "The blue curve is the quadratic that we fitted to our samples.  The red curve is\n",
    "the true, noiseless distribution of targets.  We might not be that far off with our\n",
    "predictions, but you should be able to see that our predictions will vary quite\n",
    "a bit depending on *which* ten samples we happen to have used to inform our\n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384dff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# sample data points\n",
    "xs, ts = sample_data(size=(10,))\n",
    "xs_fets = poly.fit_transform(xs.reshape(-1, 1))\n",
    "\n",
    "# fit the polynomial regression model\n",
    "pm = LinearRegression().fit(xs_fets, ts)\n",
    "\n",
    "# plotting\n",
    "plt.scatter(xs, ts, color='b', marker='o', label='samples')\n",
    "plt.plot(xs_all, pm.predict(xs_fets_all), color='b', label='fitted') # fitted curve \n",
    "plt.plot(xs_all, ts_noiseless, 'r', label='true') # noiseless distribution of targets\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817b146c",
   "metadata": {},
   "source": [
    "Let's repeat this process several times to better understand how sensitive our models are to the data we select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb49d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['m','g','b','c','m','y','k','y','g','b'] #different color for each model fit\n",
    "\n",
    "for i in range(0, 10):\n",
    "    # sample data points\n",
    "    xs, ts = sample_data(size=(10,))\n",
    "    xs_fets = poly.fit_transform(xs.reshape(-1, 1))\n",
    "    # fit the polynomial regression model\n",
    "    pm = LinearRegression()\n",
    "    pm.fit(xs_fets, ts)   \n",
    "    # plot the result\n",
    "    plt.plot(xs_all, pm.predict(xs_fets_all), color=colors[i], label=f'model {i+1}')\n",
    "    \n",
    "plt.plot(xs_all, ts_noiseless, 'r', label='true') #noiseless distribution of targets\n",
    "plt.legend(loc=\"lower center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56212ddc",
   "metadata": {},
   "source": [
    "This graph shows us that, while each model we have trained may fit the samples\n",
    "we selected, none reflect the true distribution of targets perfectly.  We attribute\n",
    "errors related to the sensitivity of our models to their training data to **variance**.\n",
    "The more error that is attributable to variance, the more our model has **overfit**\n",
    "our training data and the less we may expect its performance to generalize.\n",
    "\n",
    "In fact, we have the following decomposition:\n",
    "$$\\mathbb{E}[ (y - t)^2 | {\\bf x}] = (\\mathbb{E}[y_\\star - y | {\\bf x}])^2 + \\mathrm{Var}(y | {\\bf x})  + \\mathrm{Var}(t | {\\bf x})$$\n",
    "Where\n",
    "- $y_\\star = \\mathbb{E}[t | {\\bf x}]$ is the optimal prediction.\n",
    "- $\\mathbb{E}[ (y - t)^2 ]$ is the total error\n",
    "- $(\\mathbb{E}[y_\\star - y | {\\bf x}])^2$ is the bias\n",
    "- $\\mathrm{Var}(y | {\\bf x})$ is the variance\n",
    "- $\\mathrm{Var}(t | {\\bf x})$ is the irreducible error or Bayes error.\n",
    "\n",
    "Let us reconstruct this decomposition numerically. First, just like in class,\n",
    "we will fix a value of ${\\bf x}$ for our decomposition. This ${\\bf x}$ is the test\n",
    "sample that we would like to make predictions for. We will call this test sample\n",
    "`x0`.  This is an arbitrary choice, and you are welcome to change this value\n",
    "and re-run this demonstration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f45c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([10]) # choose x = 10 as our test sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af25eddd",
   "metadata": {},
   "source": [
    "Now, let's estimate the quantities $\\mathbb{E}[ (y - t)^2 ]$,\n",
    "$(\\mathbb{E}[y_\\star - y | {\\bf x}])^2$, $\\mathrm{Var}(y | {\\bf x})$, and \n",
    "$\\mathrm{Var}(t | {\\bf x})$ for our choice of ${\\bf x}$.\n",
    "\n",
    "To estimate these quantities, we will need to sample several different\n",
    "predictions $y$ for our choice of ${\\bf x}$. Thus, we will need to perform\n",
    "the sampling and model building noise several times---let's say ~1000---and\n",
    "then obtain a prediction for each of these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f449dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MODELS = 1000  # number of models we will build\n",
    "models = [LinearRegression() for i in range(NUM_MODELS)]\n",
    "ys = []\n",
    "\n",
    "for model in models:\n",
    "    xs, ts = sample_data(size=(10,))                 # sampling\n",
    "    xs_fets = poly.fit_transform(xs.reshape(-1, 1))  # feature mapping\n",
    "    model.fit(xs_fets, ts) # model fitting\n",
    "    # obtain a prediction:\n",
    "    y = model.predict(poly.fit_transform(x0.reshape(-1, 1)))\n",
    "    ys.append(y)\n",
    "ys = np.array(ys)\n",
    "\n",
    "print(ys) # print the predictions from the 1000 models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f989f986",
   "metadata": {},
   "source": [
    "This is enough for us to estimate the **variance** of our model at `x0` using these\n",
    "estimates $y_i$s, where each $y_i$ is the prediction made from the $i$th\n",
    "model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be18786",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variance:\", np.var(ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9c4e6e",
   "metadata": {},
   "source": [
    "Now, $y_\\star = \\mathbb{E}[t | {\\bf x}]$, the optimal prediction we\n",
    "can make, can be computed using our data generation distribution. (The\n",
    "benefit of using synthetic data is our ability to access values like this\n",
    "one.)\n",
    "Thus, we can also estimate the **bias** of our model at `x0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a706b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_star = get_gt(x0, noise=False)\n",
    "print(\"Bias\", np.mean(ys - y_star) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cedd7bf",
   "metadata": {},
   "source": [
    "Finally, we can either estimate the Bayes error, or read it \n",
    "directly from the way `get_gt` is implemented.\n",
    "\n",
    "**Task**: What is the (theoretical) Bayes error, which we can\n",
    "read directly from the way `get_gt` is implemented? You might find it helpful\n",
    "to look up the parameters of the `np.random.normal` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67054c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27f0208",
   "metadata": {},
   "source": [
    "We can also produce an empirical estimate by sampling a ground-truth\n",
    "value corresponding to `x0` some number of times. We will use the latter\n",
    "approach, since the sampled ground-truth values will be useful for computing\n",
    "the total error as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca054089",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_resample = get_gt(np.repeat(x0, NUM_MODELS)) # sample ts NUM_MODELs times\n",
    "print(\"Bayes Error:\", np.var(ts_resample)) # empirical estimate\n",
    "\n",
    "print(\"SUM of bias + variance + bayes error:\", np.var(ys) + np.mean(ys - y_star) ** 2 + np.var(ts_resample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5326264f",
   "metadata": {},
   "source": [
    "Now, let us estimate the total error, by comparing the predictions `ys`\n",
    "from above with the sampled ground-truth values `ts_resample`. This should\n",
    "be fairly close to the total above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7707eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Error:\", np.mean((ys - ts_resample) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8759311b",
   "metadata": {},
   "source": [
    "In case you would like experiment a bit (e.g., with different values of `x0`),\n",
    "here's the above code put in a single cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4467c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 2\n",
    "x0 = np.array([25]) \n",
    "NUM_MODELS = 1000  # number of models we will build\n",
    "\n",
    "poly = PolynomialFeatures(M)\n",
    "models = [LinearRegression() for i in range(NUM_MODELS)]\n",
    "ys = []\n",
    "for model in models:\n",
    "    xs, ts = sample_data(size=(10,))                 # sampling\n",
    "    xs_fets = poly.fit_transform(xs.reshape(-1, 1))  # feature mapping\n",
    "    model.fit(xs_fets, ts) # model fitting\n",
    "    # obtain a prediction:\n",
    "    y = model.predict(poly.fit_transform(x0.reshape(-1, 1)))\n",
    "    ys.append(y)\n",
    "ys = np.array(ys)\n",
    "\n",
    "y_star = get_gt(x0, noise=False)\n",
    "ts_resample = get_gt(np.repeat(x0, NUM_MODELS)) # sample ts NUM_MODELs times\n",
    "\n",
    "\n",
    "print(\"Bias\", np.mean(ys - y_star) ** 2)\n",
    "print(\"Variance:\", np.var(ys))\n",
    "print(\"Bayes Error:\", np.var(ts_resample), f\"(theoretical value: {25**2})\")\n",
    "print(\"SUM of bias + variance + bayes error:\", np.var(ys) + np.mean(ys - y_star) ** 2 + np.var(ts_resample))\n",
    "print(\"Total Error:\", np.mean((ys - ts_resample) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc8482b",
   "metadata": {},
   "source": [
    "Let's see how bias and variance change as we change the complexity of our model.\n",
    "In this synthetic example, we will define complexity by the degree of the polynomial\n",
    "that we use to model our data.\n",
    "\n",
    "**Task**: Complete the code below to provide an\n",
    "empirical estimate of the bias, variance, Bayes error,\n",
    "and total error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f439a4f8",
   "metadata": {
    "attributes": {
     "classes": [
      "python "
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "NUM_MODELS = 1000\n",
    "x0 = np.array([25])  # note: we could also average over a range of xsfor this analysis!\n",
    "degrees = [1, 2, 3, 4]\n",
    "\n",
    "bias, variance, bayes, total = [], [], [], []\n",
    "\n",
    "for M in degrees:\n",
    "    poly = PolynomialFeatures(M)\n",
    "    models = [LinearRegression() for i in range(NUM_MODELS)]\n",
    "    ts_resample = get_gt(np.repeat(x0, NUM_MODELS))\n",
    "\n",
    "    ys = []\n",
    "    for model in models:\n",
    "        xs, ts = sample_data(size=(10,))                 # sampling\n",
    "        xs_fets = poly.fit_transform(xs.reshape(-1, 1))  # feature mapping\n",
    "        model.fit(xs_fets, ts) # model fitting\n",
    "        # obtain a prediction:\n",
    "        y = model.predict(poly.fit_transform(x0.reshape(-1, 1)))\n",
    "        ys.append(y)\n",
    "    ys = np.array(ys)\n",
    "\n",
    "    y_star = get_gt(x0, noise=False)\n",
    "\n",
    "    # compute the bias, variance, bayes error, and total error for \n",
    "    # the current choice of max degree M\n",
    "    bias_value = None # TODO\n",
    "    variance_value = None # TODO\n",
    "    bayes_value = None # TODO\n",
    "    total_value = None # TODO\n",
    "\n",
    "    bias.append(bias_value)\n",
    "    variance.append(variance_value)\n",
    "    bayes.append(bayes_value)\n",
    "    total.append(total_value)\n",
    "\n",
    "plt.plot(degrees, bias, 'g', label='bias')\n",
    "plt.plot(degrees, variance, 'b', label='variance')\n",
    "plt.plot(degrees, bayes, 'y', label='bayes error')\n",
    "plt.plot(degrees, total, 'r', label='total error')\n",
    "plt.xlabel(\"Degree of polynomial\")\n",
    "plt.ylabel(\"Error\") \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77860b4f",
   "metadata": {},
   "source": [
    "**Task**: Based on the figure above, explain how the bias\n",
    "and variance of the model changes depending on the choice of $M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57194a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaffac0",
   "metadata": {},
   "source": [
    "**Task**: Note that our choice of the number of training\n",
    "samples to use to build each model affects the variance of the\n",
    "model as well! How do you think the variance of our models will\n",
    "change if we *increase* the number of training samples (e.g., from\n",
    "10 to 100 or even 1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e800a3",
   "metadata": {},
   "source": [
    "People often assume that, as a rule, bias falls and variance increases as model complexity increases.\n",
    "This can lead to accuracy profiles that are shaped like a \"U\". In the case above, a \"U\" shape\n",
    "is somewhat clear.  However, \"U\" shaped error profiles are not always a given!! Empirical results\n",
    "with neural networks, in fact, show that errors may keep decreasing as networks, and the parameters\n",
    "associated with them, become wide. This suggests that there might not be a bias-variance tradeoff\n",
    "in neural networks with respect to network width, unlike was originally claimed by\n",
    "[important authors in the ML space](https://www.dam.brown.edu/people/documents/bias-variance.pdf).\n",
    "\n",
    "If you are interested in learning more about this topic,\n",
    "we suggest you look at this recent paper by [Neal et. al](https://arxiv.org/abs/1810.08591).\n",
    "\n",
    "## Part 2. Using real data to examine Bias and Variance\n",
    "\n",
    "Now let's continue our bias/variance analysis on real data that we have seen in the past,\n",
    "and using some of the models that we have learned thus far.\n",
    "As before we will be focusing on NHANES survey data relevant to the assessment of heart disease.\n",
    "We again refer you to the [NHANES data dictionary](https://wwwn.cdc.gov/nchs/nhanes/continuousnhanes/default.aspx)\n",
    "to better understand the data. We will not repeat the exploratory data analysis from lab 1,\n",
    "but encourage you to review the data definition and key summary.\n",
    "\n",
    "- `gender` (RIAGENDR): which is binary 2=female, 1=male\n",
    "- `race_ethnicity` (RIDRETH3): which can be 1=mexican american, 2=other hispanic, 3=white, 4=black, 6=asian, ...\n",
    "- `age` (RIDAGEYR): Age in years\n",
    "- `drink_alcohol` (ALQ101): which is binary; 1 indicates the individual reportedly drinks alcohol and 2 indicates they do not\n",
    "- `blood_cholesterol` (LBDTCSI): Results of an individual's blood cholesterol tests (mmol of cholesterol/L of blood)\n",
    "- `blood_pressure_sys` (BPXSY1): an individual's systolic blood pressure\n",
    "- `diastolic_bp` (BPXDI1): an individual's diastolic blood pressure\n",
    "- `calories` (DR1TKCAL): the number of calories an individual eats per day\n",
    "- `BMI` (BMXBMI): an individual's Body Mass Index (which can be used to assess obesity)\n",
    "- `chest_pain_ever` (CDQ001): If an individual has ever reported chest pain.\n",
    "- `family_income` (INDFMPIR): Ratio of a family's income to poverty threshold\n",
    "\n",
    "We will be using these features to predict the column `target_heart`:\n",
    "\n",
    "- `target_heart`: An individual reports that they have heart disease (1=yes, 0=no)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7abcb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://URL/TO/NHANES-heart.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a csv file as a *pandas data frame*\n",
    "data = pd.read_csv(\"NHANES-heart.csv\")\n",
    "\n",
    "# display a dataframe\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93b5ce0",
   "metadata": {},
   "source": [
    "Like in lab 1 and 2, we will use indicator features for categorical values and add a bias parameter in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    \"gender_female\", \n",
    "    \"re_hispanic\", \n",
    "    \"re_white\",\n",
    "    \"re_black\",\n",
    "    \"re_asian\",\n",
    "    \"chest_pain\",\n",
    "    \"drink_alcohol\",\n",
    "    \"age\",\n",
    "    \"blood_cholesterol\",\n",
    "    \"BMI\",\n",
    "    \"blood_pressure_sys\",\n",
    "    \"diastolic_bp\",\n",
    "    \"calories\",\n",
    "    \"family_income\"]\n",
    "\n",
    "data_fets = np.stack([\n",
    "    data[\"gender\"] == 2, \n",
    "    (data[\"race_ethnicity\"] == 1) + (data[\"race_ethnicity\"] == 2),\n",
    "    data[\"race_ethnicity\"] == 3,  \n",
    "    data[\"race_ethnicity\"] == 4,\n",
    "    data[\"race_ethnicity\"] == 6,\n",
    "    data[\"chest_pain_ever\"] == 2,\n",
    "    data[\"drink_alcohol\"] == 2,\n",
    "    data[\"age\"],\n",
    "    data[\"blood_cholesterol\"],\n",
    "    data[\"BMI\"],\n",
    "    data[\"blood_pressure_sys\"],\n",
    "    data[\"diastolic_bp\"],\n",
    "    data[\"calories\"],\n",
    "    data[\"family_income\"]\n",
    "], axis=1)\n",
    "\n",
    "print(data_fets.shape) # Should be (8000, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a3e52",
   "metadata": {},
   "source": [
    "Like before, we can separate our data into training, validation, and test sets.\n",
    "We will use the same code as we did in lab 1. Just like in lab 1, we will\n",
    "normalize our data set since some of the classifiers we use will depend on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e3e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into X (dependent variables) and t (response variable)\n",
    "X = data_fets\n",
    "t = np.array(data[\"target_heart\"])\n",
    "\n",
    "# First, we will use `train_test_split` to split the data set into\n",
    "# 6500 training+validation, and 1500 test:\n",
    "X_tv, X_test, t_tv, t_test = train_test_split(X, t, test_size=1500/8000, random_state=1)\n",
    "\n",
    "# Then, use `train_test_split` to split the training+validation data\n",
    "# into 5000 train and 1500 validation\n",
    "X_train, X_valid, t_train, t_valid= train_test_split(X_tv, t_tv, test_size=1500/6500, random_state=1)\n",
    "\n",
    "# Normalization\n",
    "numerical_value_start = 7\n",
    "mean = X_train[:, numerical_value_start:].mean(axis=0)\n",
    "std = X_train[:, numerical_value_start:].std(axis=0)\n",
    "\n",
    "X_train_norm = X_train.copy()\n",
    "X_valid_norm = X_valid.copy()\n",
    "X_test_norm = X_test.copy()\n",
    "X_train_norm[:, numerical_value_start:] = (X_train[:, numerical_value_start:] - mean) / std\n",
    "X_valid_norm[:, numerical_value_start:] = (X_valid[:, numerical_value_start:] - mean) / std\n",
    "X_test_norm[:, numerical_value_start:] = (X_test[:, numerical_value_start:] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b578aaea",
   "metadata": {},
   "source": [
    "Now, we are ready to build some models to understand the various sources of error.\n",
    "We will work with these three classifiers, which we have previously experimented with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d98950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2308d099",
   "metadata": {},
   "source": [
    "**Task**:\n",
    "Unlike with synthetic data, we will not be able to produce empirical estimates of\n",
    "the bias and the Bayes error. Why is that? Why is it that we *are* able to\n",
    "estimate the variance of our classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84982efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b566132",
   "metadata": {},
   "source": [
    "**Task**: Complete the function below, which fits a classifier several\n",
    "times, each time sampling a small training set (without replacement) from\n",
    "`X_train_norm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94feb1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_variance(model, ntries=100, nsample=200):\n",
    "    \"\"\"\n",
    "    Estimate the variance of a classifier on the NHANES data set.\n",
    "\n",
    "    Parameters:\n",
    "        `model` - an sklearn model supporting the methods fit(), \n",
    "                  predict(), and score()\n",
    "        `ntries` - number of times to train the classifier to compute\n",
    "                   the classifier's variance.\n",
    "        `nsamples` - number of data points to sample to train each\n",
    "                     classifier\n",
    "\n",
    "    Returns: A tuple containing the average training error,\n",
    "             average validation error, and variance estimate.\n",
    "    \"\"\"\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    ys = []\n",
    "    for i in range(ntries):\n",
    "        subset = random.sample(range(5000), nsample)\n",
    "        model.fit(X_train_norm[subset], t_train[subset])\n",
    "        ys.append(model.predict(X_valid_norm))\n",
    "        train_acc.append(model.score(X_train_norm[subset], t_train[subset]))\n",
    "        val_acc.append(model.score(X_valid_norm, t_valid))\n",
    "    ys = np.stack(ys)\n",
    "    variances = None # TODO: Compute the variance of each row of ys, i.e., for \n",
    "                     #       each validation data point separate. (Why? Why can't\n",
    "                     #       we compute the variance of the entire ys?)\n",
    "    train_error = None # TODO: the average training error across the ntries models\n",
    "    val_error = None # TODO: the average validation error across the ntries models\n",
    "    return train_error, val_error, variances.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb9945",
   "metadata": {},
   "source": [
    "Now, we will use this function to see how the training error, validation error, and\n",
    "variance changes with our choice of hyper-parameters.\n",
    "\n",
    "**Task**: The `LogisticRegression` classifier model has a parameter `C`.\n",
    "Read the sklearn API documentation and explain what this parameter `C` does, assuming\n",
    "that L2 regularization is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e705187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97780675",
   "metadata": {},
   "source": [
    "**Task**: Run the code below to explore how the `C` parameter\n",
    "of a `LogisticRegression` affects the training error, validation error,\n",
    "and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f9dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_res = []\n",
    "cs = np.arange(-5, 2, 0.2)\n",
    "\n",
    "for c_exp in cs:\n",
    "    model = LogisticRegression(random_state=0, penalty='l2', C=10**(c_exp))\n",
    "    train_error, val_error, variance = estimate_variance(model)\n",
    "    cs_res.append([train_error, val_error, variance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aefc1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Logistic Regression\")\n",
    "plt.plot(cs, [r[0] for r in cs_res], label=\"train error\")\n",
    "plt.plot(cs, [r[1] for r in cs_res], label=\"val error\")\n",
    "plt.plot(cs, [r[2] for r in cs_res], label=\"variance\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.xlabel(\"log_10 C\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1446369b",
   "metadata": {},
   "source": [
    "**Task**: How does the `C` parameter affect the training error, validation error,\n",
    "and variance of the trained model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef20d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17de1687",
   "metadata": {},
   "source": [
    "**Task**: Run the code below, which explores how the number of hidden units\n",
    "in a 2-layer neural network affects training error, validation error,\n",
    "and variance.\n",
    "(You might get some `Stochastic Optimizer` errors saying that the optimization\n",
    "have not converged. Please ignore those.\n",
    "We are also reducing `ntries` so this code runs faster.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c3cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_res = []\n",
    "hidden_sizes = range(1, 21)\n",
    "\n",
    "for h in hidden_sizes:\n",
    "    model = MLPClassifier(alpha=0,                 # set regularization parameter to 0\n",
    "                          hidden_layer_sizes=(h,), # use only 1 hidden layer with h units\n",
    "                          learning_rate_init=0.1,  # increase LR from the default\n",
    "                          max_iter=200)\n",
    "    train_error, val_error, variance = estimate_variance(model, ntries=10)\n",
    "    mlp_res.append([train_error, val_error, variance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13721743",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Multi-Layer Perceptron\")\n",
    "plt.plot(hidden_sizes, [r[0] for r in mlp_res], label=\"train error\")\n",
    "plt.plot(hidden_sizes, [r[1] for r in mlp_res], label=\"val error\")\n",
    "plt.plot(hidden_sizes, [r[2] for r in mlp_res], label=\"variance\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.xlabel(\"hidden size\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7853498c",
   "metadata": {},
   "source": [
    "**Task**: How does the number of units in the hidden size affect the\n",
    "training error, validation error, and variance of the trained model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528688a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c84b7f",
   "metadata": {},
   "source": [
    "**Task**: Run the code below to explore how the `max_depth` parameter\n",
    "of a `DecisionTreeClassifier` affects the training error, validation error,\n",
    "and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8afcc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_res = []\n",
    "depths = list(range(1,21))\n",
    "for max_depth in depths:\n",
    "    model = DecisionTreeClassifier(random_state=0, max_depth=max_depth)\n",
    "    train_error, val_error, variance = estimate_variance(model)\n",
    "    tree_res.append([train_error, val_error, variance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab0e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Decision Tree\")\n",
    "plt.plot(depths, [r[0] for r in tree_res], label=\"train error\")\n",
    "plt.plot(depths, [r[1] for r in tree_res], label=\"val error\")\n",
    "plt.plot(depths, [r[2] for r in tree_res], label=\"variance\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5bfe87",
   "metadata": {},
   "source": [
    "**Task**: How does the `max_depth` parameter affect the training error, validation error,\n",
    "and variance of the trained model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ced4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22fbc73",
   "metadata": {},
   "source": [
    "We saw in lab 1 that hyperparameters interact with each other in\n",
    "unpredictable ways (e.g., max depth, min split, and the split criteria\n",
    "for a decision tree classifier). The analysis we conduct in this\n",
    "lab focuses on a single hyperparameter at a time, but keep in\n",
    "mind that a **grid search** is required to properly tune sets of\n",
    "hyperparameters.\n",
    "\n",
    "## Part 3. Ensemble Methods\n",
    "\n",
    "**Ensemble methods** is a family of ideas that involve \n",
    "averaging together the predictions of many models, instead\n",
    "of using a single model.\n",
    "In this section, we will analyze the impact of model averaging,\n",
    "and explore the `RandomForest` classifier.\n",
    "\n",
    "**Task**: Complete the function below, which is a modification\n",
    "of the `estimate_variance` function, that computes the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_averaging(model, ntries=100, nsample=200):\n",
    "    \"\"\"\n",
    "    Fits model a number of times on a subset of the NHANES data \n",
    "    set, and returns the average validation error of the\n",
    "    individual models, along with the validation error of the\n",
    "    average prediction of the models.\n",
    "\n",
    "    Parameters:\n",
    "        `model` - an sklearn model supporting the methods fit(), \n",
    "                  predict(), and score()\n",
    "        `ntries` - number of times to train the classifier\n",
    "        `nsamples` - number of data points to sample to train each\n",
    "                     classifier\n",
    "\n",
    "    Returns: A tuple containing the average validation error\n",
    "             across the individual models, and the validation\n",
    "             error of the average prediction of the models.\n",
    "    \"\"\"\n",
    "\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    ys = []\n",
    "    for i in range(ntries):\n",
    "        subset = random.sample(range(5000), nsample)\n",
    "        model.fit(X_train_norm[subset], t_train[subset])\n",
    "        ys.append(model.predict(X_valid_norm))\n",
    "        train_acc.append(model.score(X_train_norm[subset], t_train[subset]))\n",
    "        val_acc.append(model.score(X_valid_norm, t_valid))\n",
    "    ys = np.stack(ys)\n",
    "\n",
    "    # compute the average validation error across the individual models\n",
    "    avg_val_error = None\n",
    "    \n",
    "    # compute the average prediction across all models, and convert\n",
    "    # into a discrete prediction (0 or 1 for each data point in the\n",
    "    # validation set)\n",
    "    ys_average = None\n",
    "\n",
    "    # compute the validation error using ys_average and t_valid\n",
    "    ensemble_val_error  = None\n",
    "    \n",
    "    return avg_val_error, ensemble_val_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f02434d",
   "metadata": {},
   "source": [
    "**Task**: Run the code below, which uses the function we wrote to\n",
    "analyze how model averaging affects the validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ca7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"====== Logistic Regression Models ======\")\n",
    "cs = np.arange(-5, 2, 0.2)\n",
    "for c_exp in cs:\n",
    "    model = LogisticRegression(random_state=0, penalty='l2', C=10**(c_exp))\n",
    "    avg_val_error, ensemble_val_error = model_averaging(model)\n",
    "    print(f\"C=10**{c_exp}\", avg_val_error, ensemble_val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"====== Decision Trees ======\")\n",
    "depths = list(range(1,21))\n",
    "for max_depth in depths:\n",
    "    model = DecisionTreeClassifier(random_state=0, max_depth=max_depth)\n",
    "    avg_val_error, ensemble_val_error = model_averaging(model)\n",
    "    print(f\"max_depth={max_depth}\", avg_val_error, ensemble_val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MLP code is also included. You can optionally uncomment\n",
    "# and run this code for your interest. However, these models tend to be more\n",
    "# expensive to train, and are less often used in an ensemble.\n",
    "\n",
    "# print(\"====== MultiLayer Perceptrons  ======\")\n",
    "# hidden_sizes = range(1, 21)\n",
    "# for h in hidden_sizes:\n",
    "#     model = MLPClassifier(alpha=0,  # regularization parameter\n",
    "#                           hidden_layer_sizes=(h,),\n",
    "#                           learning_rate_init=0.01,\n",
    "#                           max_iter=200)\n",
    "#     avg_val_error, ensemble_val_error = model_averaging(model, ntries=10)\n",
    "#     print(f\"hidden_size={h}\", avg_val_error, ensemble_val_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1894bf7",
   "metadata": {},
   "source": [
    "**Task**: Analyze the pattern above.\n",
    "You should see that ensemble models tend to\n",
    "perform better or the individual models.\n",
    "Discuss the patterns you see as to which models tend to achieve\n",
    "lower validation error in an ensemble,\n",
    "and the amount of variance and total error that these models tend\n",
    "to have (from the previous results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e46c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73836fe0",
   "metadata": {},
   "source": [
    "You should see that decision trees perform quite well as an ensemble.\n",
    "While individual trees are rarely used in practice, \n",
    "an ensemble of trees tend to work well with little\n",
    "tuning. Let's now explore the `RandomForestClassifier`, which trains\n",
    "an ensemble of trees, with some additional randomness baked into\n",
    "the model to make the predictions less correlated.\n",
    "\n",
    "\n",
    "**Task**: Run the below code, which explores how the number of\n",
    "individual trees in a random forest classifier affects the\n",
    "training error, validation error, and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d54b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_res = []\n",
    "num_trees = [1, 2, 5, 10, 25, 50]\n",
    "for n in num_trees:\n",
    "    model = RandomForestClassifier(n_estimators=n)\n",
    "    train_error, val_error, variance = estimate_variance(model, ntries=10, nsample=1000)\n",
    "    forest_res.append([train_error, val_error, variance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed8dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Random Forest\")\n",
    "plt.plot(num_trees, [r[0] for r in forest_res], label=\"train error\")\n",
    "plt.plot(num_trees, [r[1] for r in forest_res], label=\"val error\")\n",
    "plt.plot(num_trees, [r[2] for r in forest_res], label=\"variance\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce22fd",
   "metadata": {},
   "source": [
    "**Task**: How does the number of trees affect the variance\n",
    "of a random forest classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11dda0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277891c8",
   "metadata": {},
   "source": [
    "**Task**: Finally, run the code below, which trains a random forest\n",
    "classifier on the entire training set, and computes the training\n",
    "and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67744a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=50)\n",
    "model.fit(X_train_norm, t_train)\n",
    "print(\"Training Accuracy:\", model.score(X_train_norm, t_train))\n",
    "print(\"Validation Accuracy:\", model.score(X_valid_norm, t_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382c4e04",
   "metadata": {},
   "source": [
    "**Task**: As in the synthetic task, the availability of data can\n",
    "also impact model performance.\n",
    "Explain how changing the amount of training data would affect model\n",
    "performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explanation of different amounts of training data has on model performance, bias/variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb79e8c",
   "metadata": {},
   "source": [
    "In reality, there are many more factors that can affect model performance.\n",
    "Training models, especially in healthcare, can be a difficult process. In\n",
    "this lab you relied on training and validation accuracy as a measure of\n",
    "model performance. But relying on just accuracy as a metric does perfectly\n",
    "reflect if a certain model is useful or appropriate.\n",
    "\n",
    "In healthcare, we care about minimizing errors that are more dangerous to\n",
    "our patients, and de-prioritize errors that have little known adverse effect.\n",
    "Similarly, there can be other factors to take into account when making\n",
    "decisions. A certain decision may algorithmically seem like the most\n",
    "optimal, but we need to take into account a patient's history and\n",
    "personality. Prescribing a certain intervention may not work on certain\n",
    "individuals, or certain patients may not be comfortable with certain\n",
    "decisions regardless of the \"accuracy\". \n",
    "\n",
    "Accuracy as a metric has many shortcomings, and a good reference for further\n",
    "reading can be found [here](https://predictive-optimization.cs.princeton.edu/).\n",
    "It is important in the future to always consider alternative metrics instead of\n",
    "solely relying on accuracy."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
